<!DOCTYPE html>
<html>
<title> The IM^2 Lab </title>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
<link rel="shortcut icon" type="image/x-icon" href="../images/logos/iconsquare.svg" />
<br>

<!-- Navbar (sit on top) -->
<div class="w3-top">
  <div class="w3-bar w3-white w3-wide w3-padding w3-card">
    <a href="../" class="w3-bar-item w3-button">
              <img class="w3-image" src="../images/logos/main_logo.svg" width="40" height="40"> Intelligent Mobile Manipulation Lab</a>
    <!-- Float links to the right. Hide them on small screens -->
    <div class="w3-right w3-hide-small">
      <!--a href="#Research" class="w3-bar-item w3-button">Research</a-->
      <a href="../people/" class="w3-bar-item w3-button">People</a>
      <a href="../opportunities/" class="w3-bar-item w3-button">Opportunities</a>
      <a href="../publications/" class="w3-bar-item w3-button">Publications</a>
    </div>
  </div>
</div>

<style>
.aligncenter {
    text-align: center;
}
</style>

<style>
p {
  font-size:17.6px;
  margin-left:250px;
  margin-right:250px;
  font-family:Cabin
}
</style>
<div class="w3-content w3-padding" style="max-width:1564px">
  <div class="w3-container w3-padding-32" id="about">
  <p>
  We develop artificial intelligence of mobile-manipulation robots to endow them with the capabilities that
    come naturally to humans. Our methodology is to
  tightly integrate learning, reasoning, and modelling to create adaptive robots that utilize both
  prior knowledge and experience to effectively operate in novel and unstructured environments.
  </p>

  <p> <strong> Perception for sequential robot manipulation  </strong> </p>
  <p style="text-align:center;">
  <iframe width="360" height="215" src="https://www.youtube.com/embed/7sIypyaZtMk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <iframe width="360" height="215" src="https://www.youtube.com/embed/CKOTcHZe4WU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <p> One fundamental capability of a mobile-manipulator is computing a sequence of manipulation
    motions to move an object given a perceptual input. While deep learning techniques has had
    significant impact on computer vision tasks,
    their impact on manipulation planning has been limited due to challenges
    that arise from motion feasibility, sequentiality, and representation. We are developing
    an integrated learning and reasoning methods that use deep learning to
    process high-dimensional sensory data to predict appropriate subgoals and motion constraints,
    and use motion planning to compute compute sequential manipulation motions to manipulate a diverse set of
    novel objects.  </p>
  </p>

  <p> <strong> Learning to guide task and motion planning </strong> </p>
  <p style="text-align:center;">
  <iframe width="360" height="215" src="https://www.youtube.com/embed/_u8JfiB6l0w" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
  <iframe width="360" height="215" src="https://www.youtube.com/embed/5GK75ar80DE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <p> AlphaGo had a tremendous success in the game of Go by integrating planning
    with reinforcement learning (RL). Planning enabled the Go-playing agent
    to deliberately choose a move among many choices, while RL enabled the agent to prioritize promising moves
    efficiently from experience. We apply this insight to task and motion planning problems,
    where the robot has to manipulate multiple objects to achieve a high-level goal. In particular,
    we are developing representation, planning, and learning algorithms to deal with the fact that
    the robot faces a real-world environment instead of a game board.
    </p>
  </p>



</div>
</div>



</body>
</html>